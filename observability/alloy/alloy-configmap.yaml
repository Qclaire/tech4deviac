apiVersion: v1
kind: ConfigMap
metadata:
  name: alloy-config
  namespace: alloy
  labels:
    app.kubernetes.io/name: alloy
data:
  config.alloy: |-
    logging {
      level = "info"
      format = "logfmt"
    }

    loki.write "my_loki" {
      endpoint {
        url = "http://loki-gateway.default.svc.cluster.local:80/loki/api/v1/push"
      }
      external_labels = {cluster = "kind-labs"}
    }

    prometheus.remote_write "to_mimir" {
      endpoint {
        url = "http://mimir-nginx.mimir.svc.cluster.local:80/api/v1/push"
      }
    }

    discovery.kubernetes "k8s" {
      role = "node"
    }

    prometheus.scrape "kubernetes_cadvisor" {
      targets = discovery.kubernetes.k8s.targets
      scheme = "https"
      bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
      tls_config {
        insecure_skip_verify = true
      }
      scrape_interval = "30s"
      forward_to = [prometheus.remote_write.to_mimir.receiver]
    }

    local.file_match "containerd_logs" {
      path_targets = [{"__path__" = "/var/log/pods/*/*/*.log"}]
      sync_period = "5s"
    }

    loki.source.file "log_scrape" {
      targets = local.file_match.containerd_logs.targets
      forward_to = [loki.write.my_loki.receiver]
    }

    // Feature: Cluster Events
    declare "cluster_events" {
      argument "logs_destinations" {
        comment = "Must be a list of log destinations where collected logs should be forwarded to"
      }

      loki.source.kubernetes_events "cluster_events" {
        job_name   = "integrations/kubernetes/eventhandler"
        log_format = "logfmt"
        namespaces = ["meta","prod","vault","default","alloy","mimir"]
        forward_to = [loki.process.cluster_events.receiver]
      }

      loki.process "cluster_events" {

        // add a static source label to the logs so they can be differentiated / restricted if necessary
        stage.static_labels {
          values = {
            "source" = "kubernetes-events",
          }
        }

        // extract some of the fields from the log line, these could be used as labels, structured metadata, etc.
        stage.logfmt {
          mapping = {
            "component" = "sourcecomponent", // map the sourcecomponent field to component
            "kind" = "",
            "level" = "type", // most events don't have a level but they do have a "type" i.e. Normal, Warning, Error, etc.
            "name" = "",
            "node" = "sourcehost", // map the sourcehost field to node
          }
        }
        // set these values as labels, they may or may not be used as index labels in Loki as they can be dropped
        // prior to being written to Loki, but this makes them available
        stage.labels {
          values = {
            "component" = "",
            "kind" = "",
            "level" = "",
            "name" = "",
            "node" = "",
          }
        }

        // if kind=Node, set the node label by copying the instance label
        stage.match {
          selector = "{kind=\"Node\"}"

          stage.labels {
            values = {
              "node" = "name",
            }
          }
        }

        // set the level extracted key value as a normalized log level
        stage.match {
          selector = "{level=\"Normal\"}"

          stage.static_labels {
            values = {
              level = "Info",
            }
          }
        }

        // Only keep the labels that are defined in the `keepLabels` list.
        stage.label_keep {
          values = ["job","level","namespace","node","source"]
        }
        stage.labels {
          values = {
            "service_name" = "job",
          }
        }
        forward_to = argument.logs_destinations.value
      }
    }
    cluster_events "feature" {
      logs_destinations = [
        loki.write.loki.receiver,
      ]
    }
    // Feature: Pod Logs
    declare "pod_logs" {
      argument "logs_destinations" {
        comment = "Must be a list of log destinations where collected logs should be forwarded to"
      }

      discovery.relabel "filtered_pods" {
        targets = discovery.kubernetes.pods.targets
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          action = "replace"
          target_label = "namespace"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_name"]
          action = "replace"
          target_label = "pod"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_container_name"]
          action = "replace"
          target_label = "container"
        }
        rule {
          source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_container_name"]
          separator = "/"
          action = "replace"
          replacement = "$1"
          target_label = "job"
        }

        // set the container runtime as a label
        rule {
          action = "replace"
          source_labels = ["__meta_kubernetes_pod_container_id"]
          regex = "^(\\S+):\\/\\/.+$"
          replacement = "$1"
          target_label = "tmp_container_runtime"
        }

        // make all labels on the pod available to the pipeline as labels,
        // they are omitted before write to loki via stage.label_keep unless explicitly set
        rule {
          action = "labelmap"
          regex = "__meta_kubernetes_pod_label_(.+)"
        }

        // make all annotations on the pod available to the pipeline as labels,
        // they are omitted before write to loki via stage.label_keep unless explicitly set
        rule {
          action = "labelmap"
          regex = "__meta_kubernetes_pod_annotation_(.+)"
        }

        // explicitly set service_name. if not set, loki will automatically try to populate a default.
        // see https://grafana.com/docs/loki/latest/get-started/labels/#default-labels-for-all-users
        //
        // choose the first value found from the following ordered list:
        // - pod.annotation[resource.opentelemetry.io/service.name]
        // - pod.label[app.kubernetes.io/name]
        // - k8s.pod.name
        // - k8s.container.name
        rule {
          action = "replace"
          source_labels = [
            "__meta_kubernetes_pod_annotation_resource_opentelemetry_io_service_name",
            "__meta_kubernetes_pod_label_app_kubernetes_io_name",
            "__meta_kubernetes_pod_name",
            "__meta_kubernetes_pod_container_name",
          ]
          separator = ";"
          regex = "^(?:;*)?([^;]+).*$"
          replacement = "$1"
          target_label = "service_name"
        }

        // set resource attributes
        rule {
          action = "labelmap"
          regex = "__meta_kubernetes_pod_annotation_resource_opentelemetry_io_(.+)"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_k8s_grafana_com_logs_job"]
          regex = "(.+)"
          target_label = "job"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
          regex = "(.+)"
          target_label = "app_kubernetes_io_name"
        }
      }

      discovery.kubernetes "pods" {
        role = "pod"
        namespaces {
          names = ["meta","vault","prod","default","alloy","mimir"]
        }
      }

      loki.source.kubernetes "pod_logs" {
        targets = discovery.relabel.filtered_pods.output
        forward_to = [loki.process.pod_logs.receiver]
      }

      loki.process "pod_logs" {
        stage.match {
          selector = "{tmp_container_runtime=~\"containerd|cri-o\"}"
          // the cri processing stage extracts the following k/v pairs: log, stream, time, flags
          stage.cri {}

          // Set the extract flags and stream values as labels
          stage.labels {
            values = {
              flags  = "",
              stream  = "",
            }
          }
        }

        stage.match {
          selector = "{tmp_container_runtime=\"docker\"}"
          // the docker processing stage extracts the following k/v pairs: log, stream, time
          stage.docker {}

          // Set the extract stream value as a label
          stage.labels {
            values = {
              stream  = "",
            }
          }
        }

        // Drop the filename label, since it's not really useful in the context of Kubernetes, where we already have cluster,
        // namespace, pod, and container labels. Drop any structured metadata. Also drop the temporary
        // container runtime label as it is no longer needed.
        stage.label_drop {
          values = [
            "filename",
            "tmp_container_runtime",
          ]
        }
        // set the structured metadata values
        stage.structured_metadata {
          values = {
            "pod" = "pod",
          }
        }

        // Only keep the labels that are defined in the `keepLabels` list.
        stage.label_keep {
          values = ["app_kubernetes_io_name","container","instance","job","level","namespace","service_name","service_namespace","deployment_environment","deployment_environment_name"]
        }

        forward_to = argument.logs_destinations.value
      }
    }
    pod_logs "feature" {
      logs_destinations = [
        loki.write.loki.receiver,
      ]
    }




    // Destination: loki (loki)
    otelcol.exporter.loki "loki" {
      forward_to = [loki.write.loki.receiver]
    }

    loki.write "loki" {
      endpoint {
        url = "http://loki-gateway.default.svc.cluster.local/loki/api/v1/push"
        tls_config {
          insecure_skip_verify = false
        }
        min_backoff_period = "500ms"
        max_backoff_period = "5m"
        max_backoff_retries = "10"
        headers = {
          "X-Scope-OrgID" = "1",
        }
      }
      external_labels = {
        "cluster" = "kind-labs",
        "k8s_cluster_name" = "kind-labs",
      }
    }
